import torch
import numpy as np
import cv2
import os
import time
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    accuracy_score, precision_recall_fscore_support, 
    confusion_matrix, classification_report, roc_auc_score
)
from video_transformer_model import VideoTransformer
import json
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

class VideoTransformerTester:
    """Class ƒë·ªÉ test hi·ªáu su·∫•t c·ªßa VideoTransformer model"""
    
    def __init__(self, model_path: str, device: str = 'auto', model_type: str = 'auto'):
        """
        Args:
            model_path: ƒê∆∞·ªùng d·∫´n t·ªõi model file (.ckpt ho·∫∑c .pth)
            device: 'auto', 'cpu', ho·∫∑c 'cuda'
            model_type: 'auto', 'ckpt', ho·∫∑c 'pth' - t·ª± ƒë·ªông detect n·∫øu 'auto'
        """
        self.model_path = model_path
        self.device = self._get_device(device)
        self.model_type = self._detect_model_type(model_path, model_type)
        self.model = None
        self.class_names = ['B√¨nh th∆∞·ªùng', 'Gian l·∫≠n']
        
        print(f"üöÄ Kh·ªüi t·∫°o VideoTransformer Tester")
        print(f"üì± Device: {self.device}")
        print(f"üéØ Model path: {model_path}")
        print(f"üìÑ Model type: {self.model_type}")
        
    def _get_device(self, device: str) -> str:
        """T·ª± ƒë·ªông ch·ªçn device"""
        if device == 'auto':
            return 'cuda' if torch.cuda.is_available() else 'cpu'
        return device
    
    def _detect_model_type(self, model_path: str, model_type: str) -> str:
        """T·ª± ƒë·ªông detect lo·∫°i model t·ª´ extension"""
        if model_type != 'auto':
            return model_type
        
        if model_path.endswith('.ckpt'):
            return 'ckpt'
        elif model_path.endswith('.pth') or model_path.endswith('.pt'):
            return 'pth'
        else:
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ detect model type t·ª´ {model_path}, s·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh 'ckpt'")
            return 'ckpt'
    
    def load_model(self) -> bool:
        """Load model t·ª´ checkpoint ho·∫∑c pth file"""
        try:
            print(f"üì• ƒêang load model t·ª´ {self.model_path}...")
            
            if not os.path.exists(self.model_path):
                print(f"‚ùå Kh√¥ng t√¨m th·∫•y file model: {self.model_path}")
                return False
            
            size_mb = os.path.getsize(self.model_path) / (1024 * 1024)
            print(f"üìä Model size: {size_mb:.1f} MB")
            
            if self.model_type == 'ckpt':
                # Load model t·ª´ PyTorch Lightning checkpoint
                print(f"üîß Loading PyTorch Lightning checkpoint...")
                try:
                    # Th·ª≠ load v·ªõi Lightning loader tr∆∞·ªõc
                    self.model = VideoTransformer.load_from_checkpoint(
                        self.model_path,
                        map_location=self.device,
                        strict=False
                    )
                except Exception as e1:
                    print(f"‚ö†Ô∏è Lightning loader failed: {e1}")
                    print(f"üîÑ Trying manual load...")
                    
                    # Fallback: load manual
                    checkpoint = torch.load(self.model_path, map_location=self.device)
                    
                    # T·∫°o model v·ªõi hyperparameters
                    if 'hyper_parameters' in checkpoint:
                        hparams = checkpoint['hyper_parameters']
                        print(f"üìã Using hyperparameters from checkpoint")
                    else:
                        # Default hyperparameters
                        hparams = {
                            'img_size': 224,
                            'patch_size': 16,
                            'in_channels': 3,
                            'num_classes': 2,
                            'embed_dim': 768,
                            'num_heads': 12,
                            'num_layers': 12,
                            'num_frames': 8,
                            'mlp_ratio': 4.0,
                            'dropout': 0.1,
                            'learning_rate': 1e-4
                        }
                        print(f"ÔøΩ Using default hyperparameters")
                    
                    self.model = VideoTransformer(**hparams)
                    
                    # Load state dict
                    if 'state_dict' in checkpoint:
                        state_dict = checkpoint['state_dict']
                    else:
                        state_dict = checkpoint
                    
                    # Remove 'model.' prefix if exists
                    new_state_dict = {}
                    for k, v in state_dict.items():
                        if k.startswith('model.'):
                            new_state_dict[k[6:]] = v
                        else:
                            new_state_dict[k] = v
                    
                    self.model.load_state_dict(new_state_dict, strict=False)
                    
            elif self.model_type == 'pth':
                # Load model t·ª´ PyTorch pth file
                print(f"üîß Loading t·ª´ .pth file...")
                model_kwargs = {
                    'img_size': 224,
                    'patch_size': 16,
                    'in_channels': 3,
                    'num_classes': 2,
                    'embed_dim': 768,
                    'num_heads': 12,
                    'num_layers': 12,
                    'num_frames': 8,
                    'mlp_ratio': 4.0,
                    'dropout': 0.1,
                    'learning_rate': 1e-4
                }
                self.model = VideoTransformer.load_from_pth(
                    self.model_path, 
                    device=self.device,
                    **model_kwargs
                )
            else:
                print(f"‚ùå Kh√¥ng h·ªó tr·ª£ model type: {self.model_type}")
                return False
            
            self.model.eval()
            self.model.to(self.device)
            
            # Test forward pass
            print(f"üß™ Testing model forward pass...")
            with torch.no_grad():
                dummy_input = torch.randn(1, 3, 8, 224, 224).to(self.device)
                try:
                    output = self.model(dummy_input)
                    print(f"‚úÖ Forward test successful! Output shape: {output.shape}")
                except Exception as e:
                    print(f"‚ùå Forward test failed: {e}")
                    return False
            
            print(f"‚úÖ Load model th√†nh c√¥ng!")
            print(f"üîß Model parameters: {sum(p.numel() for p in self.model.parameters()):,}")
            print(f"üéÆ Model device: {next(self.model.parameters()).device}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå L·ªói khi load model: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_single_video(self, video_path: str, true_label: int = None) -> Dict:
        """Test m·ªôt video ƒë∆°n l·∫ª"""
        if self.model is None:
            print("‚ùå Model ch∆∞a ƒë∆∞·ª£c load!")
            return {}
        
        print(f"\nüé¨ Testing video: {os.path.basename(video_path)}")
        
        start_time = time.time()
        
        try:
            # D·ª± ƒëo√°n
            predicted_class, confidence = self.model.predict_video(video_path, self.device)
            
            if predicted_class is None:
                print(f"‚ùå Kh√¥ng th·ªÉ x·ª≠ l√Ω video: {video_path}")
                return {}
            
            inference_time = time.time() - start_time
            
            result = {
                'video_path': video_path,
                'predicted_class': predicted_class,
                'predicted_label': self.class_names[predicted_class],
                'confidence': confidence,
                'inference_time': inference_time
            }
            
            if true_label is not None:
                result['true_label'] = true_label
                result['true_class_name'] = self.class_names[true_label]
                result['correct'] = predicted_class == true_label
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            print(f"üéØ D·ª± ƒëo√°n: {self.class_names[predicted_class]} ({confidence:.4f})")
            if true_label is not None:
                print(f"üè∑Ô∏è  Th·ª±c t·∫ø: {self.class_names[true_label]}")
                print(f"‚úÖ Ch√≠nh x√°c: {'ƒê√∫ng' if result['correct'] else 'Sai'}")
            print(f"‚è±Ô∏è  Th·ªùi gian: {inference_time:.3f}s")
            
            return result
            
        except Exception as e:
            print(f"‚ùå L·ªói khi test video: {str(e)}")
            return {}
    
    def test_video_folder(self, folder_path: str, label_mapping: Dict[str, int] = None) -> Dict:
        """
        Test to√†n b·ªô folder video
        
        Args:
            folder_path: ƒê∆∞·ªùng d·∫´n t·ªõi folder ch·ª©a video
            label_mapping: Dict mapping t√™n subfolder -> label (0: b√¨nh th∆∞·ªùng, 1: gian l·∫≠n)
                          V√≠ d·ª•: {'normal': 0, 'fraud': 1}
        """
        if self.model is None:
            print("‚ùå Model ch∆∞a ƒë∆∞·ª£c load!")
            return {}
        
        print(f"\nüìÅ Testing folder: {folder_path}")
        
        video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv'}
        all_results = []
        
        if label_mapping:
            # Test theo structure subfolder
            for class_folder, label in label_mapping.items():
                class_path = os.path.join(folder_path, class_folder)
                if not os.path.exists(class_path):
                    print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y folder: {class_path}")
                    continue
                
                print(f"\nüìÇ Testing class: {class_folder} (label: {label})")
                
                video_files = [
                    f for f in os.listdir(class_path) 
                    if Path(f).suffix.lower() in video_extensions
                ]
                
                for video_file in video_files:
                    video_path = os.path.join(class_path, video_file)
                    result = self.test_single_video(video_path, label)
                    if result:
                        all_results.append(result)
        else:
            # Test t·∫•t c·∫£ video trong folder (kh√¥ng c√≥ ground truth)
            video_files = [
                f for f in os.listdir(folder_path) 
                if Path(f).suffix.lower() in video_extensions
            ]
            
            for video_file in video_files:
                video_path = os.path.join(folder_path, video_file)
                result = self.test_single_video(video_path)
                if result:
                    all_results.append(result)
        
        return self._analyze_results(all_results)
    
    def _analyze_results(self, results: List[Dict]) -> Dict:
        """Ph√¢n t√≠ch k·∫øt qu·∫£ test"""
        if not results:
            print("‚ùå Kh√¥ng c√≥ k·∫øt qu·∫£ ƒë·ªÉ ph√¢n t√≠ch!")
            return {}
        
        analysis = {
            'total_videos': len(results),
            'results': results,
            'avg_inference_time': np.mean([r['inference_time'] for r in results]),
            'avg_confidence': np.mean([r['confidence'] for r in results])
        }
        
        # N·∫øu c√≥ ground truth labels
        if 'true_label' in results[0]:
            true_labels = [r['true_label'] for r in results]
            pred_labels = [r['predicted_class'] for r in results]
            confidences = [r['confidence'] for r in results]
            
            # T√≠nh metrics
            accuracy = accuracy_score(true_labels, pred_labels)
            precision, recall, f1, support = precision_recall_fscore_support(
                true_labels, pred_labels, average='weighted'
            )
            
            # Confusion matrix
            cm = confusion_matrix(true_labels, pred_labels)
            
            # Classification report
            class_report = classification_report(
                true_labels, pred_labels, 
                target_names=self.class_names,
                output_dict=True
            )
            
            analysis.update({
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'confusion_matrix': cm.tolist(),
                'classification_report': class_report,
                'correct_predictions': sum(r['correct'] for r in results)
            })
            
            # ROC AUC n·∫øu c√≥ ƒë·ªß classes
            if len(set(true_labels)) == 2:
                try:
                    # S·ª≠ d·ª•ng confidence c·ªßa class 1 (gian l·∫≠n) l√†m probability
                    probs = [conf if pred == 1 else 1-conf for pred, conf in zip(pred_labels, confidences)]
                    auc = roc_auc_score(true_labels, probs)
                    analysis['auc'] = auc
                except:
                    pass
        
        self._print_analysis(analysis)
        return analysis
    
    def _print_analysis(self, analysis: Dict):
        """In k·∫øt qu·∫£ ph√¢n t√≠ch"""
        print(f"\n{'='*60}")
        print(f"üìä K·∫æT QU·∫¢ PH√ÇN T√çCH HI·ªÜU SU·∫§T")
        print(f"{'='*60}")
        
        print(f"üìà T·ªïng s·ªë video: {analysis['total_videos']}")
        print(f"‚è±Ô∏è  Th·ªùi gian trung b√¨nh: {analysis['avg_inference_time']:.3f}s/video")
        print(f"üéØ Confidence trung b√¨nh: {analysis['avg_confidence']:.4f}")
        
        if 'accuracy' in analysis:
            print(f"\nüéØ HI·ªÜU SU·∫§T PH√ÇN LO·∫†I:")
            print(f"   ‚Ä¢ Accuracy: {analysis['accuracy']:.4f} ({analysis['accuracy']*100:.2f}%)")
            print(f"   ‚Ä¢ Precision: {analysis['precision']:.4f}")
            print(f"   ‚Ä¢ Recall: {analysis['recall']:.4f}")
            print(f"   ‚Ä¢ F1-Score: {analysis['f1_score']:.4f}")
            
            if 'auc' in analysis:
                print(f"   ‚Ä¢ AUC: {analysis['auc']:.4f}")
            
            print(f"   ‚Ä¢ D·ª± ƒëo√°n ƒë√∫ng: {analysis['correct_predictions']}/{analysis['total_videos']}")
            
            # Confusion Matrix
            cm = np.array(analysis['confusion_matrix'])
            print(f"\nüìã CONFUSION MATRIX:")
            print(f"                    Predicted")
            print(f"                B√¨nh th∆∞·ªùng  Gian l·∫≠n")
            print(f"Actual B√¨nh th∆∞·ªùng    {cm[0,0]:4d}      {cm[0,1]:4d}")
            print(f"       Gian l·∫≠n       {cm[1,0]:4d}      {cm[1,1]:4d}")
            
            # Per-class metrics
            print(f"\nüìä CHI TI·∫æT THEO CLASS:")
            for class_name in self.class_names:
                class_idx = self.class_names.index(class_name)
                if str(class_idx) in analysis['classification_report']:
                    metrics = analysis['classification_report'][str(class_idx)]
                    print(f"   {class_name}:")
                    print(f"     - Precision: {metrics['precision']:.4f}")
                    print(f"     - Recall: {metrics['recall']:.4f}")
                    print(f"     - F1-Score: {metrics['f1-score']:.4f}")
                    print(f"     - Support: {metrics['support']}")
    
    def save_results(self, results: Dict, output_path: str):
        """L∆∞u k·∫øt qu·∫£ ra file JSON"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"üíæ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {output_path}")
        except Exception as e:
            print(f"‚ùå L·ªói khi l∆∞u file: {str(e)}")
    
    def plot_confusion_matrix(self, results: Dict, save_path: str = None):
        """V·∫Ω confusion matrix"""
        if 'confusion_matrix' not in results:
            print("‚ùå Kh√¥ng c√≥ confusion matrix ƒë·ªÉ v·∫Ω!")
            return
        
        plt.figure(figsize=(8, 6))
        cm = np.array(results['confusion_matrix'])
        
        sns.heatmap(
            cm, 
            annot=True, 
            fmt='d', 
            cmap='Blues',
            xticklabels=self.class_names,
            yticklabels=self.class_names
        )
        
        plt.title('Confusion Matrix')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"üìä ƒê√£ l∆∞u confusion matrix: {save_path}")
        
        plt.show()
    
    def benchmark_speed(self, video_path: str, num_runs: int = 10):
        """Benchmark t·ªëc ƒë·ªô x·ª≠ l√Ω"""
        if self.model is None:
            print("‚ùå Model ch∆∞a ƒë∆∞·ª£c load!")
            return
        
        print(f"\n‚ö° BENCHMARK T·ªêC ƒê·ªò ({num_runs} l·∫ßn ch·∫°y)")
        print(f"üìπ Video: {os.path.basename(video_path)}")
        
        times = []
        for i in range(num_runs):
            start_time = time.time()
            self.model.predict_video(video_path, self.device)
            inference_time = time.time() - start_time
            times.append(inference_time)
            print(f"Run {i+1:2d}: {inference_time:.3f}s")
        
        print(f"\nüìä TH·ªêNG K√ä T·ªêC ƒê·ªò:")
        print(f"   ‚Ä¢ Trung b√¨nh: {np.mean(times):.3f}s")
        print(f"   ‚Ä¢ T·ªëi thi·ªÉu: {np.min(times):.3f}s")
        print(f"   ‚Ä¢ T·ªëi ƒëa: {np.max(times):.3f}s")
        print(f"   ‚Ä¢ ƒê·ªô l·ªách chu·∫©n: {np.std(times):.3f}s")
        print(f"   ‚Ä¢ FPS t∆∞∆°ng ƒë∆∞∆°ng: {1/np.mean(times):.2f} video/s")

def demo_test():
    """Demo function ƒë·ªÉ test model"""
    print("üé¨ VideoTransformer Model Tester Demo")
    print("="*50)
    
    # C·∫•u h√¨nh - Th·ª≠ c√°c ƒë∆∞·ªùng d·∫´n model c√≥ s·∫µn
    MODEL_PATHS = [
        r"C:\Users\anhvu\Documents\linh tinh\epoch=4-step=75.ckpt",  # PyTorch Lightning checkpoint
        r"C:\Users\anhvu\Documents\linh tinh\vivit_model.pth",       # PyTorch model file
        "video_transformer_model.ckpt",  # Fallback
    ]
    
    DEVICE = 'auto'  # 'auto', 'cpu', ho·∫∑c 'cuda'
    
    # T√¨m model file c√≥ s·∫µn
    model_path = None
    for path in MODEL_PATHS:
        if os.path.exists(path):
            model_path = path
            print(f"‚úÖ T√¨m th·∫•y model: {os.path.basename(path)}")
            break
    
    if not model_path:
        print("‚ùå Kh√¥ng t√¨m th·∫•y model file n√†o!")
        print("üí° C√°c ƒë∆∞·ªùng d·∫´n ƒë√£ th·ª≠:")
        for path in MODEL_PATHS:
            print(f"   - {path}")
        return
    
    # Kh·ªüi t·∫°o tester
    tester = VideoTransformerTester(model_path, DEVICE)
    
    # Load model
    if not tester.load_model():
        print("‚ùå Kh√¥ng th·ªÉ load model. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
        return
    
    # Test cases kh√°c nhau
    print("\n" + "="*50)
    print("üéØ CH·ªåN LO·∫†I TEST:")
    print("1. Test m·ªôt video ƒë∆°n l·∫ª")
    print("2. Test folder video c√≥ c·∫•u tr√∫c")
    print("3. Test folder video kh√¥ng c√≥ nh√£n")
    print("4. Benchmark t·ªëc ƒë·ªô")
    
    choice = input("\nNh·∫≠p l·ª±a ch·ªçn (1-4): ").strip()
    
    if choice == '1':
        # Test single video
        video_path = input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n video: ").strip()
        has_label = input("Video c√≥ ground truth label kh√¥ng? (y/n): ").lower().startswith('y')
        
        true_label = None
        if has_label:
            true_label = int(input("Nh·∫≠p label (0: B√¨nh th∆∞·ªùng, 1: Gian l·∫≠n): "))
        
        result = tester.test_single_video(video_path, true_label)
        
        # L∆∞u k·∫øt qu·∫£
        if result:
            tester.save_results(result, 'single_video_result.json')
    
    elif choice == '2':
        # Test folder with structure
        folder_path = input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n folder: ").strip()
        print("\nC·∫•u tr√∫c folder c·∫ßn c√≥ d·∫°ng:")
        print("folder/")
        print("  ‚îú‚îÄ‚îÄ normal/     (video b√¨nh th∆∞·ªùng)")
        print("  ‚îî‚îÄ‚îÄ fraud/      (video gian l·∫≠n)")
        
        label_mapping = {
            'normal': 0,
            'fraud': 1
        }
        
        results = tester.test_video_folder(folder_path, label_mapping)
        
        # L∆∞u k·∫øt qu·∫£ v√† v·∫Ω bi·ªÉu ƒë·ªì
        if results:
            tester.save_results(results, 'folder_test_results.json')
            tester.plot_confusion_matrix(results, 'confusion_matrix.png')
    
    elif choice == '3':
        # Test folder without labels
        folder_path = input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n folder: ").strip()
        results = tester.test_video_folder(folder_path)
        
        if results:
            tester.save_results(results, 'unlabeled_test_results.json')
    
    elif choice == '4':
        # Benchmark speed
        video_path = input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n video ƒë·ªÉ benchmark: ").strip()
        num_runs = int(input("S·ªë l·∫ßn ch·∫°y (m·∫∑c ƒë·ªãnh 10): ") or "10")
        tester.benchmark_speed(video_path, num_runs)
    
    else:
        print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")

if __name__ == "__main__":
    demo_test()
